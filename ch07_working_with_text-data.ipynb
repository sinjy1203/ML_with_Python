{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0153b309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "matplotlib.rc('font', family='NanumBarunGothic')\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54e414fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "if not os.path.isfile('data/aclImdb_v1.tar.gz'):\n",
    "    !wget -q http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz -P data\n",
    "    !tar -xzf data/aclImdb_v1.tar.gz -C data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bafb6d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "ap = tarfile.open(\"./data/aclImdb_v1.tar.gz\")\n",
    "ap.extractall(\"./data\")\n",
    "ap.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05cd0297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree('data/aclImdb/train/unsup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a523099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list,\n",
       " 25000,\n",
       " b'Words can\\'t describe how bad this movie is. I can\\'t explain it by writing only. You have too see it for yourself to get at grip of how horrible a movie really can be. Not that I recommend you to do that. There are so many clich\\xc3\\xa9s, mistakes (and all other negative things you can imagine) here that will just make you cry. To start with the technical first, there are a LOT of mistakes regarding the airplane. I won\\'t list them here, but just mention the coloring of the plane. They didn\\'t even manage to show an airliner in the colors of a fictional airline, but instead used a 747 painted in the original Boeing livery. Very bad. The plot is stupid and has been done many times before, only much, much better. There are so many ridiculous moments here that i lost count of it really early. Also, I was on the bad guys\\' side all the time in the movie, because the good guys were so stupid. \"Executive Decision\" should without a doubt be you\\'re choice over this one, even the \"Turbulence\"-movies are better. In fact, every other movie in the world is better than this one.')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "\n",
    "reviews_train = load_files(\"data/aclImdb/train/\")\n",
    "text_train, y_train = reviews_train.data, reviews_train.target\n",
    "type(text_train), len(text_train), text_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62823b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc3c80b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = [doc.replace(b\"<br />\", b\" \") for doc in text_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34efd010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12500, 12500], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.bincount(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23d30727",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_test = load_files(\"data/aclImdb/test/\")\n",
    "text_test, y_test = reviews_test.data, reviews_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e289e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63820839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12500, 12500], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd45040",
   "metadata": {},
   "source": [
    "## BOW ( bag of words )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "688febcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bards_words = [\"The fool doth think he is wise,\",\n",
    "              \"but the wise man knows himself to be a fool\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59ec3325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "vect.fit(bards_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9577e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd4eda7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 9,\n",
       " 'fool': 3,\n",
       " 'doth': 2,\n",
       " 'think': 10,\n",
       " 'he': 4,\n",
       " 'is': 6,\n",
       " 'wise': 12,\n",
       " 'but': 1,\n",
       " 'man': 8,\n",
       " 'knows': 7,\n",
       " 'himself': 5,\n",
       " 'to': 11,\n",
       " 'be': 0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab57492c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1],\n",
       "       [1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words = vect.transform(bards_words)\n",
    "bag_of_words.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b001000b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25000x74849 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3431196 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer().fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cae625f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74849"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e1e501f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74849"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = vect.get_feature_names_out()\n",
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67b15fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aesir', 'aesop', 'aestheically', 'aesthete', 'aesthetic',\n",
       "       'aesthetical', 'aesthetically', 'aestheticism', 'aesthetics',\n",
       "       'aetheist'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names[2000:2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a9e22e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88124"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "scores = cross_val_score(LogisticRegression(max_iter=1000), X_train, y_train, n_jobs=-1)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c4d0c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8881599999999998, {'C': 0.1})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "grid = GridSearchCV(LogisticRegression(max_iter=5000), param_grid, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "grid.best_score_, grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2927d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87892"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = vect.transform(text_test)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e646358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25000x27271 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3354014 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(min_df=5).fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0770e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vect.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3afdc08f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '000', '007', '00s', '01', '02', '03', '04', '05', '06',\n",
       "       '07', '08', '09', '10', '100', '1000', '100th', '101', '102',\n",
       "       '103', '104', '105', '107', '108', '10s', '10th', '11', '110',\n",
       "       '112', '116', '117', '11th', '12', '120', '12th', '13', '135',\n",
       "       '13th', '14', '140', '14th', '15', '150', '15th', '16', '160',\n",
       "       '1600', '16mm', '16s', '16th'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5aabf1a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['repentance', 'repercussions', 'repertoire', 'repetition',\n",
       "       'repetitions', 'repetitious', 'repetitive', 'rephrase', 'replace',\n",
       "       'replaced', 'replacement', 'replaces', 'replacing', 'replay',\n",
       "       'replayable', 'replayed', 'replaying', 'replays', 'replete',\n",
       "       'replica'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names[20010:20030]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3c12e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['zwick', 'émigré'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9361555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.88812, {'C': 0.1})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(LogisticRegression(max_iter=5000), param_grid, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "grid.best_score_, grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f94600",
   "metadata": {},
   "source": [
    "## 불용어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "261d2a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318,\n",
       " ['are',\n",
       "  'without',\n",
       "  'along',\n",
       "  'third',\n",
       "  'amongst',\n",
       "  'thence',\n",
       "  'may',\n",
       "  'it',\n",
       "  'by',\n",
       "  'four',\n",
       "  'onto',\n",
       "  'seem',\n",
       "  'toward',\n",
       "  'take',\n",
       "  'us',\n",
       "  'done',\n",
       "  'below',\n",
       "  'of',\n",
       "  'part',\n",
       "  'indeed',\n",
       "  'eleven',\n",
       "  'your',\n",
       "  'once',\n",
       "  'whereas',\n",
       "  'thereby',\n",
       "  'eg',\n",
       "  'few',\n",
       "  'was',\n",
       "  'sometimes',\n",
       "  'get',\n",
       "  'wherein',\n",
       "  'formerly'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "len(ENGLISH_STOP_WORDS), list(ENGLISH_STOP_WORDS)[::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a29d9128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25000x26966 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2149958 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(min_df=5, stop_words=\"english\").fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2477851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8828400000000001, {'C': 0.1})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(LogisticRegression(max_iter=5000), param_grid, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "grid.best_score_, grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1f5fa2",
   "metadata": {},
   "source": [
    "## tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "22829489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.89192, {'logisticregression__C': 10})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(TfidfVectorizer(min_df=5), LogisticRegression(max_iter=5000))\n",
    "param_grid = {'logisticregression__C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, n_jobs=-1)\n",
    "grid.fit(text_train, y_train)\n",
    "grid.best_score_, grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c84bf0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['suplexes', 'gauche', 'hypocrites', 'oncoming', 'songwriting',\n",
       "       'galadriel', 'emerald', 'mclaughlin', 'sylvain', 'oversee',\n",
       "       'cataclysmic', 'pressuring', 'uphold', 'thieving', 'inconsiderate',\n",
       "       'ware', 'denim', 'reverting', 'booed', 'spacious'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = grid.best_estimator_.named_steps['tfidfvectorizer']\n",
    "X_train = vectorizer.transform(text_train)\n",
    "max_value = X_train.max(axis=0).toarray().ravel()\n",
    "sorted_by_tfidf = max_value.argsort()\n",
    "feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "feature_names[sorted_by_tfidf[:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e05e435a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gadget', 'sucks', 'zatoichi', 'demons', 'lennon', 'bye', 'dev',\n",
       "       'weller', 'sasquatch', 'botched', 'xica', 'darkman', 'woo',\n",
       "       'casper', 'doodlebops', 'smallville', 'wei', 'scanners', 'steve',\n",
       "       'pokemon'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names[sorted_by_tfidf[-20:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c0bf4224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['the', 'and', 'of', 'to', 'this', 'is', 'it', 'in', 'that', 'but',\n",
       "       'for', 'with', 'was', 'as', 'on', 'movie', 'not', 'have', 'one',\n",
       "       'be', 'film', 'are', 'you', 'all', 'at', 'an', 'by', 'so', 'from',\n",
       "       'like', 'who', 'they', 'there', 'if', 'his', 'out', 'just',\n",
       "       'about', 'he', 'or', 'has', 'what', 'some', 'good', 'can', 'more',\n",
       "       'when', 'time', 'up', 'very', 'even', 'only', 'no', 'would', 'my',\n",
       "       'see', 'really', 'story', 'which', 'well', 'had', 'me', 'than',\n",
       "       'much', 'their', 'get', 'were', 'other', 'been', 'do', 'most',\n",
       "       'don', 'her', 'also', 'into', 'first', 'made', 'how', 'great',\n",
       "       'because', 'will', 'people', 'make', 'way', 'could', 'we', 'bad',\n",
       "       'after', 'any', 'too', 'then', 'them', 'she', 'watch', 'think',\n",
       "       'acting', 'movies', 'seen', 'its', 'him'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_by_idf = np.argsort(vectorizer.idf_)\n",
    "feature_names[sorted_by_idf[:100]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02def0e",
   "metadata": {},
   "source": [
    "## 여러 단어로 만든 BOW(n-그램)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "53c21655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The fool doth think he is wise,',\n",
       " 'but the wise man knows himself to be a fool']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bards_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2d58cf18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13,\n",
       " array(['be', 'but', 'doth', 'fool', 'he', 'himself', 'is', 'knows', 'man',\n",
       "        'the', 'think', 'to', 'wise'], dtype=object))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(ngram_range=(1, 1)).fit(bards_words)\n",
    "len(cv.vocabulary_), cv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "349676e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14,\n",
       " array(['be fool', 'but the', 'doth think', 'fool doth', 'he is',\n",
       "        'himself to', 'is wise', 'knows himself', 'man knows', 'the fool',\n",
       "        'the wise', 'think he', 'to be', 'wise man'], dtype=object))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(ngram_range=(2, 2)).fit(bards_words)\n",
    "len(cv.vocabulary_), cv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e71c729a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27,\n",
       " array(['be', 'be fool', 'but', 'but the', 'doth', 'doth think', 'fool',\n",
       "        'fool doth', 'he', 'he is', 'himself', 'himself to', 'is',\n",
       "        'is wise', 'knows', 'knows himself', 'man', 'man knows', 'the',\n",
       "        'the fool', 'the wise', 'think', 'think he', 'to', 'to be', 'wise',\n",
       "        'wise man'], dtype=object))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(ngram_range=(1, 2)).fit(bards_words)\n",
    "len(cv.vocabulary_), cv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7add8a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9064400000000001,\n",
       " {'logisticregression__C': 100, 'tfidfvectorizer__ngram_range': (1, 3)})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = make_pipeline(TfidfVectorizer(min_df=5), LogisticRegression(max_iter=5000))\n",
    "param_grid = {'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100], \n",
    "             'tfidfvectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)]}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, n_jobs=-1)\n",
    "grid.fit(text_train, y_train)\n",
    "grid.best_score_, grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be82a98f",
   "metadata": {},
   "source": [
    "## 어간추출 표제어추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92fc3e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.3.5', '3.7')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "\n",
    "spacy.__version__, nltk.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99edde69",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_nlp = spacy.load('en_core_web_sm')\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "\n",
    "def compare_normalization(doc):\n",
    "    doc_spacy = en_nlp(doc)\n",
    "    print(\"표제어: \")\n",
    "    print([token.lemma_ for token in doc_spacy])\n",
    "    print(\"어간:\")\n",
    "    print([stemmer.stem(token.norm_.lower()) for token in doc_spacy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f56530f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "표제어: \n",
      "['-PRON-', 'meeting', 'today', 'be', 'bad', 'than', 'yesterday', ',', '-PRON-', 'be', 'scared', 'of', 'meet', 'the', 'client', 'tomorrow', '.']\n",
      "어간:\n",
      "['our', 'meet', 'today', 'wa', 'wors', 'than', 'yesterday', ',', 'i', 'am', 'scare', 'of', 'meet', 'the', 'client', 'tomorrow', '.']\n"
     ]
    }
   ],
   "source": [
    "compare_normalization(u\"Our meeting today was worse than yesterday, \"\n",
    "                       \"I'm scared of meeting the clients tomorrow.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad1fc04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "en_nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "def custom_tokenizer(document):\n",
    "    doc_spacy = en_nlp(document)\n",
    "    return [token.lemma_ for token in doc_spacy]\n",
    "\n",
    "lemma_vect = CountVectorizer(tokenizer=custom_tokenizer, min_df=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d95aef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 22100)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_lemma = lemma_vect.fit_transform(text_train)\n",
    "X_train_lemma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76091cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 27271)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(min_df=5).fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0df4cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7187717171717172"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.99,\n",
    "                           train_size=0.01, random_state=0)\n",
    "grid = GridSearchCV(LogisticRegression(max_iter=5000), param_grid, cv=cv, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1095d616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7187151515151514"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train_lemma, y_train)\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c969e8bc",
   "metadata": {},
   "source": [
    "## KoNLPy를 이용한 영화리뷰분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47224e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import konlpy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1c464ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.6.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "konlpy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d5f9d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('data/ratings_train.txt', delimiter='\\t', keep_default_na=False)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad9c1114",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train, y_train = df_train['document'].values, df_train['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "584c0b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('data/ratings_test.txt', delimiter='\\t', keep_default_na=False)\n",
    "text_test, y_test = df_test['document'].values, df_test['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "296802c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, array([75173, 74827], dtype=int64))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_train), np.bincount(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "631afc52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, array([24827, 25173], dtype=int64))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_test), np.bincount(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cadba69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "class PickableOkt(Okt):\n",
    "    def __init__(self, *args):\n",
    "        self.args = args\n",
    "        Okt.__init__(self, *args)\n",
    "    def __setstate__(self, state):\n",
    "        self.__init__(*state['args'])\n",
    "    def __getstate__(self):\n",
    "        return {'args': self.args}\n",
    "    \n",
    "okt = PickableOkt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c57ed105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.718,\n",
       " {'logisticregression__C': 1,\n",
       "  'tfidfvectorizer__min_df': 3,\n",
       "  'tfidfvectorizer__ngram_range': (1, 3)})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'tfidfvectorizer__min_df': [3, 5, 7], \n",
    "             'tfidfvectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)], \n",
    "             'logisticregression__C': [0.1, 1, 10]}\n",
    "pipe = make_pipeline(TfidfVectorizer(tokenizer=okt.morphs), \n",
    "                    LogisticRegression())\n",
    "grid = GridSearchCV(pipe, param_grid, n_jobs=-1)\n",
    "\n",
    "grid.fit(text_train[:1000], y_train[:1000])\n",
    "grid.best_score_, grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bb41398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.714"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfvectorizer = grid.best_estimator_.named_steps['tfidfvectorizer']\n",
    "X_test = tfidfvectorizer.transform(text_test[:1000])\n",
    "logisticregression = grid.best_estimator_.named_steps['logisticregression']\n",
    "score = logisticregression.score(X_test, y_test[:1000])\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80b67453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.714"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(text_test[:1000], y_test[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd1ae05",
   "metadata": {},
   "source": [
    "## 토픽 모델링과 문서 군집화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "604847c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C:/Users/sinjy/jupyter_notebook/datasets/aclImdb_v2.tar.gz',\n",
       " <http.client.HTTPMessage at 0x1ff2da2b988>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib import request\n",
    "\n",
    "url = \"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "request.urlretrieve(url, \"C:/Users/sinjy/jupyter_notebook/datasets/aclImdb_v2.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a8aeb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "ap = tarfile.open(\"C:/Users/sinjy/jupyter_notebook/datasets/aclImdb_v2.tar.gz\")\n",
    "ap.extractall(\"C:/Users/sinjy/jupyter_notebook/datasets\")\n",
    "ap.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36204b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "aclImdb_dir = Path(\"C:/Users/sinjy/jupyter_notebook/datasets/aclImdb\")\n",
    "shutil.rmtree(aclImdb_dir / 'train/unsup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94514886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list,\n",
       " 25000,\n",
       " b'Words can\\'t describe how bad this movie is. I can\\'t explain it by writing only. You have too see it for yourself to get at grip of how horrible a movie really can be. Not that I recommend you to do that. There are so many clich\\xc3\\xa9s, mistakes (and all other negative things you can imagine) here that will just make you cry. To start with the technical first, there are a LOT of mistakes regarding the airplane. I won\\'t list them here, but just mention the coloring of the plane. They didn\\'t even manage to show an airliner in the colors of a fictional airline, but instead used a 747 painted in the original Boeing livery. Very bad. The plot is stupid and has been done many times before, only much, much better. There are so many ridiculous moments here that i lost count of it really early. Also, I was on the bad guys\\' side all the time in the movie, because the good guys were so stupid. \"Executive Decision\" should without a doubt be you\\'re choice over this one, even the \"Turbulence\"-movies are better. In fact, every other movie in the world is better than this one.')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "\n",
    "reviews_train = load_files(aclImdb_dir / \"train/\")\n",
    "text_train, y_train = reviews_train.data, reviews_train.target\n",
    "type(text_train), len(text_train), text_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad991cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = [doc.replace(b\"<br />\", b\" \") for doc in text_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "291d81ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12500, 12500], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de1be7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_test = load_files(aclImdb_dir / \"test/\")\n",
    "text_test, y_test = reviews_test.data, reviews_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87bc961b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test = [doc.replace(b\"<br />\", b\" \") for doc in text_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1215242f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12500, 12500], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac4cfac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5674b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(max_features=10000, max_df=.15)\n",
    "X = vect.fit_transform(text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "332624bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 10000)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "965be8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda = LatentDirichletAllocation(n_components=10, learning_method=\"batch\",\n",
    "                               max_iter=25, random_state=0, n_jobs=-1)\n",
    "document_topics = lda.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b54ac28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 10)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_topics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2aaf0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10000)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cbf4e756",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda100 = LatentDirichletAllocation(n_components=100, learning_method='batch',\n",
    "                                  max_iter=25, random_state=0, n_jobs=-1)\n",
    "document_topics100 = lda100.fit_transform(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning",
   "language": "python",
   "name": "machine-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
