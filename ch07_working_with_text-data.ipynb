{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0153b309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "matplotlib.rc('font', family='NanumBarunGothic')\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54e414fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "if not os.path.isfile('data/aclImdb_v1.tar.gz'):\n",
    "    !wget -q http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz -P data\n",
    "    !tar -xzf data/aclImdb_v1.tar.gz -C data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bafb6d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "ap = tarfile.open(\"./data/aclImdb_v1.tar.gz\")\n",
    "ap.extractall(\"./data\")\n",
    "ap.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05cd0297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree('data/aclImdb/train/unsup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a523099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list,\n",
       " 25000,\n",
       " b'Words can\\'t describe how bad this movie is. I can\\'t explain it by writing only. You have too see it for yourself to get at grip of how horrible a movie really can be. Not that I recommend you to do that. There are so many clich\\xc3\\xa9s, mistakes (and all other negative things you can imagine) here that will just make you cry. To start with the technical first, there are a LOT of mistakes regarding the airplane. I won\\'t list them here, but just mention the coloring of the plane. They didn\\'t even manage to show an airliner in the colors of a fictional airline, but instead used a 747 painted in the original Boeing livery. Very bad. The plot is stupid and has been done many times before, only much, much better. There are so many ridiculous moments here that i lost count of it really early. Also, I was on the bad guys\\' side all the time in the movie, because the good guys were so stupid. \"Executive Decision\" should without a doubt be you\\'re choice over this one, even the \"Turbulence\"-movies are better. In fact, every other movie in the world is better than this one.')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "\n",
    "reviews_train = load_files(\"data/aclImdb/train/\")\n",
    "text_train, y_train = reviews_train.data, reviews_train.target\n",
    "type(text_train), len(text_train), text_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62823b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc3c80b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = [doc.replace(b\"<br />\", b\" \") for doc in text_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34efd010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12500, 12500], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.bincount(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23d30727",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_test = load_files(\"data/aclImdb/test/\")\n",
    "text_test, y_test = reviews_test.data, reviews_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e289e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63820839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12500, 12500], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd45040",
   "metadata": {},
   "source": [
    "## BOW ( bag of words )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "688febcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bards_words = [\"The fool doth think he is wise,\",\n",
    "              \"but the wise man knows himself to be a fool\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59ec3325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "vect.fit(bards_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9577e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd4eda7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 9,\n",
       " 'fool': 3,\n",
       " 'doth': 2,\n",
       " 'think': 10,\n",
       " 'he': 4,\n",
       " 'is': 6,\n",
       " 'wise': 12,\n",
       " 'but': 1,\n",
       " 'man': 8,\n",
       " 'knows': 7,\n",
       " 'himself': 5,\n",
       " 'to': 11,\n",
       " 'be': 0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab57492c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1],\n",
       "       [1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words = vect.transform(bards_words)\n",
    "bag_of_words.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b001000b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25000x74849 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3431196 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer().fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cae625f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74849"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e1e501f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74849"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = vect.get_feature_names_out()\n",
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67b15fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aesir', 'aesop', 'aestheically', 'aesthete', 'aesthetic',\n",
       "       'aesthetical', 'aesthetically', 'aestheticism', 'aesthetics',\n",
       "       'aetheist'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names[2000:2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a9e22e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88124"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "scores = cross_val_score(LogisticRegression(max_iter=1000), X_train, y_train, n_jobs=-1)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c4d0c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8881599999999998, {'C': 0.1})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "grid = GridSearchCV(LogisticRegression(max_iter=5000), param_grid, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "grid.best_score_, grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2927d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87892"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = vect.transform(text_test)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e646358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25000x27271 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3354014 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(min_df=5).fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0770e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vect.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3afdc08f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '000', '007', '00s', '01', '02', '03', '04', '05', '06',\n",
       "       '07', '08', '09', '10', '100', '1000', '100th', '101', '102',\n",
       "       '103', '104', '105', '107', '108', '10s', '10th', '11', '110',\n",
       "       '112', '116', '117', '11th', '12', '120', '12th', '13', '135',\n",
       "       '13th', '14', '140', '14th', '15', '150', '15th', '16', '160',\n",
       "       '1600', '16mm', '16s', '16th'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5aabf1a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['repentance', 'repercussions', 'repertoire', 'repetition',\n",
       "       'repetitions', 'repetitious', 'repetitive', 'rephrase', 'replace',\n",
       "       'replaced', 'replacement', 'replaces', 'replacing', 'replay',\n",
       "       'replayable', 'replayed', 'replaying', 'replays', 'replete',\n",
       "       'replica'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names[20010:20030]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3c12e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['zwick', 'émigré'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9361555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.88812, {'C': 0.1})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(LogisticRegression(max_iter=5000), param_grid, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "grid.best_score_, grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f94600",
   "metadata": {},
   "source": [
    "## 불용어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "261d2a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318,\n",
       " ['are',\n",
       "  'without',\n",
       "  'along',\n",
       "  'third',\n",
       "  'amongst',\n",
       "  'thence',\n",
       "  'may',\n",
       "  'it',\n",
       "  'by',\n",
       "  'four',\n",
       "  'onto',\n",
       "  'seem',\n",
       "  'toward',\n",
       "  'take',\n",
       "  'us',\n",
       "  'done',\n",
       "  'below',\n",
       "  'of',\n",
       "  'part',\n",
       "  'indeed',\n",
       "  'eleven',\n",
       "  'your',\n",
       "  'once',\n",
       "  'whereas',\n",
       "  'thereby',\n",
       "  'eg',\n",
       "  'few',\n",
       "  'was',\n",
       "  'sometimes',\n",
       "  'get',\n",
       "  'wherein',\n",
       "  'formerly'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "len(ENGLISH_STOP_WORDS), list(ENGLISH_STOP_WORDS)[::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a29d9128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25000x26966 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2149958 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(min_df=5, stop_words=\"english\").fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2477851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8828400000000001, {'C': 0.1})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(LogisticRegression(max_iter=5000), param_grid, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "grid.best_score_, grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1f5fa2",
   "metadata": {},
   "source": [
    "## tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "22829489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.89192, {'logisticregression__C': 10})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(TfidfVectorizer(min_df=5), LogisticRegression(max_iter=5000))\n",
    "param_grid = {'logisticregression__C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, n_jobs=-1)\n",
    "grid.fit(text_train, y_train)\n",
    "grid.best_score_, grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c84bf0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['suplexes', 'gauche', 'hypocrites', 'oncoming', 'songwriting',\n",
       "       'galadriel', 'emerald', 'mclaughlin', 'sylvain', 'oversee',\n",
       "       'cataclysmic', 'pressuring', 'uphold', 'thieving', 'inconsiderate',\n",
       "       'ware', 'denim', 'reverting', 'booed', 'spacious'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = grid.best_estimator_.named_steps['tfidfvectorizer']\n",
    "X_train = vectorizer.transform(text_train)\n",
    "max_value = X_train.max(axis=0).toarray().ravel()\n",
    "sorted_by_tfidf = max_value.argsort()\n",
    "feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "feature_names[sorted_by_tfidf[:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e05e435a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gadget', 'sucks', 'zatoichi', 'demons', 'lennon', 'bye', 'dev',\n",
       "       'weller', 'sasquatch', 'botched', 'xica', 'darkman', 'woo',\n",
       "       'casper', 'doodlebops', 'smallville', 'wei', 'scanners', 'steve',\n",
       "       'pokemon'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names[sorted_by_tfidf[-20:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c0bf4224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['the', 'and', 'of', 'to', 'this', 'is', 'it', 'in', 'that', 'but',\n",
       "       'for', 'with', 'was', 'as', 'on', 'movie', 'not', 'have', 'one',\n",
       "       'be', 'film', 'are', 'you', 'all', 'at', 'an', 'by', 'so', 'from',\n",
       "       'like', 'who', 'they', 'there', 'if', 'his', 'out', 'just',\n",
       "       'about', 'he', 'or', 'has', 'what', 'some', 'good', 'can', 'more',\n",
       "       'when', 'time', 'up', 'very', 'even', 'only', 'no', 'would', 'my',\n",
       "       'see', 'really', 'story', 'which', 'well', 'had', 'me', 'than',\n",
       "       'much', 'their', 'get', 'were', 'other', 'been', 'do', 'most',\n",
       "       'don', 'her', 'also', 'into', 'first', 'made', 'how', 'great',\n",
       "       'because', 'will', 'people', 'make', 'way', 'could', 'we', 'bad',\n",
       "       'after', 'any', 'too', 'then', 'them', 'she', 'watch', 'think',\n",
       "       'acting', 'movies', 'seen', 'its', 'him'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_by_idf = np.argsort(vectorizer.idf_)\n",
    "feature_names[sorted_by_idf[:100]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02def0e",
   "metadata": {},
   "source": [
    "## 여러 단어로 만든 BOW(n-그램)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "53c21655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The fool doth think he is wise,',\n",
       " 'but the wise man knows himself to be a fool']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bards_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2d58cf18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13,\n",
       " array(['be', 'but', 'doth', 'fool', 'he', 'himself', 'is', 'knows', 'man',\n",
       "        'the', 'think', 'to', 'wise'], dtype=object))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(ngram_range=(1, 1)).fit(bards_words)\n",
    "len(cv.vocabulary_), cv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "349676e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14,\n",
       " array(['be fool', 'but the', 'doth think', 'fool doth', 'he is',\n",
       "        'himself to', 'is wise', 'knows himself', 'man knows', 'the fool',\n",
       "        'the wise', 'think he', 'to be', 'wise man'], dtype=object))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(ngram_range=(2, 2)).fit(bards_words)\n",
    "len(cv.vocabulary_), cv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e71c729a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27,\n",
       " array(['be', 'be fool', 'but', 'but the', 'doth', 'doth think', 'fool',\n",
       "        'fool doth', 'he', 'he is', 'himself', 'himself to', 'is',\n",
       "        'is wise', 'knows', 'knows himself', 'man', 'man knows', 'the',\n",
       "        'the fool', 'the wise', 'think', 'think he', 'to', 'to be', 'wise',\n",
       "        'wise man'], dtype=object))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(ngram_range=(1, 2)).fit(bards_words)\n",
    "len(cv.vocabulary_), cv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7add8a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9064400000000001,\n",
       " {'logisticregression__C': 100, 'tfidfvectorizer__ngram_range': (1, 3)})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = make_pipeline(TfidfVectorizer(min_df=5), LogisticRegression(max_iter=5000))\n",
    "param_grid = {'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100], \n",
    "             'tfidfvectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)]}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, n_jobs=-1)\n",
    "grid.fit(text_train, y_train)\n",
    "grid.best_score_, grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be82a98f",
   "metadata": {},
   "source": [
    "## 어간추출 표제어추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92fc3e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.3.5', '3.7')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "\n",
    "spacy.__version__, nltk.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99edde69",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_nlp = spacy.load('en_core_web_sm')\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "\n",
    "def compare_normalization(doc):\n",
    "    doc_spacy = en_nlp(doc)\n",
    "    print(\"표제어: \")\n",
    "    print([token.lemma_ for token in doc_spacy])\n",
    "    print(\"어간:\")\n",
    "    print([stemmer.stem(token.norm_.lower()) for token in doc_spacy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f56530f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "표제어: \n",
      "['-PRON-', 'meeting', 'today', 'be', 'bad', 'than', 'yesterday', ',', '-PRON-', 'be', 'scared', 'of', 'meet', 'the', 'client', 'tomorrow', '.']\n",
      "어간:\n",
      "['our', 'meet', 'today', 'wa', 'wors', 'than', 'yesterday', ',', 'i', 'am', 'scare', 'of', 'meet', 'the', 'client', 'tomorrow', '.']\n"
     ]
    }
   ],
   "source": [
    "compare_normalization(u\"Our meeting today was worse than yesterday, \"\n",
    "                       \"I'm scared of meeting the clients tomorrow.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad1fc04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "en_nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "def custom_tokenizer(document):\n",
    "    doc_spacy = en_nlp(document)\n",
    "    return [token.lemma_ for token in doc_spacy]\n",
    "\n",
    "lemma_vect = CountVectorizer(tokenizer=custom_tokenizer, min_df=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d95aef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 22100)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_lemma = lemma_vect.fit_transform(text_train)\n",
    "X_train_lemma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76091cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 27271)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(min_df=5).fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0df4cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7187717171717172"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.99,\n",
    "                           train_size=0.01, random_state=0)\n",
    "grid = GridSearchCV(LogisticRegression(max_iter=5000), param_grid, cv=cv, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1095d616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7187151515151514"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train_lemma, y_train)\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d76e26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning",
   "language": "python",
   "name": "machine-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
